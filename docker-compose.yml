version: '3.8'

services:
  immich-server:
    container_name: immich_server
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    command: [ "start.sh", "immich" ]
    volumes:
      - ${AZURE_MOUNT_PATH}/originals:/usr/src/app/upload
      - ${SSD_MOUNT_PATH}/immich/thumbs:/usr/src/app/upload/thumbs
      - ${SSD_MOUNT_PATH}/immich/encoded-video:/usr/src/app/upload/encoded-video
      - ${SSD_MOUNT_PATH}/immich/profile:/usr/src/app/upload/profile
      - ${SSD_MOUNT_PATH}/immich/upload:/usr/src/app/upload/upload
      - ${SSD_MOUNT_PATH}/immich/backups:/usr/src/app/upload/backups
      - ${AZURE_MOUNT_PATH}:/usr/src/app/external
      - /etc/localtime:/etc/localtime:ro
    env_file:
      - .env
    ports:
      - 2283:3001
    depends_on:
      - redis
      - database
    restart: always

  immich-microservices:
    container_name: immich_microservices
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    # extends:
    #   file: hwaccel.transcoding.yml
    #   service: cpu # set to one of [nvenc, quicksync, rkmpp, vaapi, vaapi-wsl] for accelerated transcoding
    command: [ "start.sh", "microservices" ]
    volumes:
      - ${AZURE_MOUNT_PATH}/originals:/usr/src/app/upload
      - ${SSD_MOUNT_PATH}/immich/thumbs:/usr/src/app/upload/thumbs
      - ${SSD_MOUNT_PATH}/immich/encoded-video:/usr/src/app/upload/encoded-video
      - ${SSD_MOUNT_PATH}/immich/profile:/usr/src/app/upload/profile
      - ${SSD_MOUNT_PATH}/immich/upload:/usr/src/app/upload/upload
      - ${SSD_MOUNT_PATH}/immich/backups:/usr/src/app/upload/backups
      - ${AZURE_MOUNT_PATH}:/usr/src/app/external
      - /etc/localtime:/etc/localtime:ro
    env_file:
      - .env
    depends_on:
      - redis
      - database
    restart: always

  immich-machine-learning:
    container_name: immich_machine_learning
    # For hardware acceleration, add one of -[armnn, cuda, openvino] to the image tag.
    # Example tag: ${IMMICH_VERSION:-release}-cuda
    image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}
    # extends: # uncomment this section for hardware acceleration - see https://immich.app/docs/features/ml-hardware-acceleration
    #   file: hwaccel.ml.yml
    #   service: cpu # set to one of [armnn, cuda, openvino, openvino-wsl] for accelerated inference - use the `-wsl` version for WSL2 where applicable
    volumes:
      - ${SSD_MOUNT_PATH}/immich/model-cache:/cache
    env_file:
      - .env
    restart: always

  redis:
    container_name: immich_redis
    image: redis:6.2-alpine
    restart: always

  database:
    container_name: immich_postgres
    image: tensorchord/pgvecto-rs:pg14-v0.2.0
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_DB: ${DB_DATABASE_NAME}
    volumes:
      - ${SSD_MOUNT_PATH}/immich/postgres:/var/lib/postgresql/data
    restart: always

  cloudflared:
    image: cloudflare/cloudflared:latest
    restart: unless-stopped
    command: tunnel run --protocol http2
    environment:
      TUNNEL_TOKEN: ${CLOUDFLARE_TUNNEL_TOKEN}
    # No ports needed for Cloudflare tunnel
    # It connects to the network internally
